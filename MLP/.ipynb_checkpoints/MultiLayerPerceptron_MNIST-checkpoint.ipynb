{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-1-02bb1e25a56c>, line 126)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-02bb1e25a56c>\"\u001b[1;36m, line \u001b[1;32m126\u001b[0m\n\u001b[1;33m    print \"building the model ...\"\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import cPickle\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        \"\"\"ロジスティック回帰モデルの初期化\n",
    "        input: ミニバッチ単位のデータ行列（n_samples, n_in）\n",
    "        n_in : 入力の次元数\n",
    "        n_out: 出力の次元数\n",
    "        \"\"\"\n",
    "        # 重み行列を初期化\n",
    "        self.W = theano.shared(value=np.zeros((n_in, n_out),\n",
    "                                              dtype=theano.config.floatX),\n",
    "                               name='W',\n",
    "                               borrow=True)\n",
    "\n",
    "        # バイアスベクトルを初期化\n",
    "        self.b = theano.shared(value=np.zeros((n_out,),\n",
    "                                              dtype=theano.config.floatX),\n",
    "                               name='b',\n",
    "                               borrow=True)\n",
    "\n",
    "        # 各サンプルが各クラスに分類される確率を計算するシンボル\n",
    "        # 全データを行列化してまとめて計算している\n",
    "        # 出力は(n_samples, n_out)の行列\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
    "\n",
    "        # 確率が最大のクラスのインデックスを計算\n",
    "        # 出力は(n_samples,)のベクトル\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "\n",
    "        # ロジスティック回帰モデルのパラメータ\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "        # 入力値\n",
    "        self._input = input\n",
    "\n",
    "    def negative_log_likelihood(self, y, x=None):\n",
    "        \"\"\"誤差関数である負の対数尤度を計算するシンボルを返す\n",
    "        yにはinputに対応する正解クラスを渡す\n",
    "        \"\"\"\n",
    "        # 式通りに計算するとsumだがmeanの方がよい\n",
    "        \n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "\n",
    "    def errors(self, y):\n",
    "        \"\"\"分類の誤差率を計算するシンボルを返す\n",
    "        yにはinputに対応する正解クラスを渡す\"\"\"\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError('y should have the same shape as self.y_pred',\n",
    "                            ('y', y.type, 'y_pred', self.y_pred.type))\n",
    "\n",
    "        if y.dtype.startswith('int'):\n",
    "            return T.mean(T.neq(self.y_pred, y))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "    def inputs(self):\n",
    "        return self._input\n",
    "    \n",
    "    def pred(self):\n",
    "        return self.y_pred\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    \"\"\"データセットをロードしてGPUの共有変数に格納\"\"\"\n",
    "    \n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    train_set, valid_set, test_set = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    def shared_dataset(data_xy, borrow=True):\n",
    "        data_x, data_y = data_xy\n",
    "\n",
    "        # 共有変数には必ずfloat型で格納\n",
    "        shared_x = theano.shared(\n",
    "            np.asarray(data_x, dtype=theano.config.floatX), borrow=borrow)\n",
    "        shared_y = theano.shared(\n",
    "            np.asarray(data_y, dtype=theano.config.floatX), borrow=borrow)\n",
    "\n",
    "        # ラベルはint型なのでキャストして返す\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "    test_set_x, test_set_y = shared_dataset(test_set)\n",
    "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "    train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "    rval = [(train_set_x, train_set_y),\n",
    "            (valid_set_x, valid_set_y),\n",
    "            (test_set_x, test_set_y)]\n",
    "\n",
    "    return rval\n",
    "\n",
    "\n",
    "def sgd_optimization_mnist(learning_rate=0.13, n_epochs=1000, batch_size=600):\n",
    "    \n",
    "    # =================================\n",
    "    # １．プリプロセス\n",
    "    # =================================\n",
    "    \n",
    "    # =================================\n",
    "    # １．１．データの読み込み\n",
    "    # =================================\n",
    "    \n",
    "    # 学習データの準備\n",
    "    datasets = load_data('mnist.pkl.gz')\n",
    "\n",
    "    train_set_x, train_set_y = datasets[0]\n",
    "    valid_set_x, valid_set_y = datasets[1]\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "    # ミニバッチの数\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "    n_test_batches = test_set_x.get_value(borrow=True).shape[0] / batch_size\n",
    "\n",
    "    print \"building the model ...\"\n",
    "\n",
    "    # =================================\n",
    "    # １．２．シンボルの設定\n",
    "    # =================================\n",
    "    \n",
    "    # シンボルの割り当て\n",
    "    # ミニバッチのインデックスを表すシンボル\n",
    "    index = T.lscalar()\n",
    "\n",
    "    # ミニバッチの学習データとラベルを表すシンボル\n",
    "    x = T.matrix('x')\n",
    "    y = T.ivector('y')\n",
    "\n",
    "    # MNISTの手書き数字を分類するロジスティック回帰モデル\n",
    "    # 入力は28ピクセルx28ピクセルの画像、出力は0から9のラベル\n",
    "    # 入力はシンボルxを割り当てておいてあとで具体的なデータに置換する\n",
    "    classifier = LogisticRegression(input=x, n_in=28 * 28, n_out=10)\n",
    "\n",
    "    # 誤差（コスト）を計算 => 最小化したい\n",
    "    cost = classifier.negative_log_likelihood(y, x)\n",
    "    \n",
    "    # =================================\n",
    "    # １．３．ミニバッチの設定\n",
    "    # =================================\n",
    "\n",
    "    # index番目のテスト用ミニバッチを入力してエラー率を返す関数を定義\n",
    "    test_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={  # ここで初めてシンボル x, y を具体的な値で置き換える\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: test_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        })\n",
    "\n",
    "    # index番目のバリデーション用ミニバッチを入力してエラー率を返す関数を定義\n",
    "    validate_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        })\n",
    "\n",
    "    # =================================\n",
    "    # １．４．式の設定\n",
    "    # =================================\n",
    "    \n",
    "    # コスト関数の各パラメータでの微分を計算\n",
    "    g_W = T.grad(cost=cost, wrt=classifier.W)\n",
    "    g_b = T.grad(cost=cost, wrt=classifier.b)\n",
    "\n",
    "    # パラメータ更新式\n",
    "    updates = [(classifier.W, classifier.W - learning_rate * g_W),\n",
    "               (classifier.b, classifier.b - learning_rate * g_b)]\n",
    "\n",
    "    # index番目の訓練バッチを入力し、パラメータを更新する関数を定義\n",
    "    # 戻り値としてコストが返される\n",
    "    # この関数の呼び出し時にindexに具体的な値が初めて渡される\n",
    "    train_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        })\n",
    "    \n",
    "    # =================================\n",
    "    # １．５．入出力を表示\n",
    "    # =================================\n",
    "    \n",
    "    # index番目のテスト用ミニバッチを入力して画素と輝度を返す関数を定義\n",
    "    test_image = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.inputs(),\n",
    "        givens={  # ここで初めてシンボル xを具体的な値で置き換える\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        })\n",
    "    \n",
    "    # 出力結果を表示\n",
    "    test_output = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.pred(),\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        })\n",
    "    \n",
    "    # =================================\n",
    "    # ２．トレーニング\n",
    "    # =================================\n",
    "\n",
    "    # =================================\n",
    "    # ２．１．パラメータ設定\n",
    "    # =================================\n",
    "    \n",
    "    # モデル訓練\n",
    "    print 'training the model ...'\n",
    "\n",
    "    # eary-stoppingのパラメータ\n",
    "    patience = 5000\n",
    "    patience_increase = 2\n",
    "    improvement_threshold = 0.995\n",
    "    validation_frequency = min(n_train_batches, patience / 2)\n",
    "\n",
    "    best_validation_loss = np.inf\n",
    "    test_score = 0\n",
    "    start_time = time.clock()\n",
    "\n",
    "    done_looping = False\n",
    "    epoch = 0\n",
    "\n",
    "    \n",
    "    while (epoch < n_epochs) and (not done_looping):\n",
    "        epoch = epoch + 1\n",
    "        for minibatch_index in xrange(n_train_batches):\n",
    "            \n",
    "            # =================================\n",
    "            # ２．２．誤差逆伝播\n",
    "            # =================================\n",
    "            \n",
    "            # minibatch_index番目の訓練データのミニバッチを用いてパラメータ更新\n",
    "            train_model(minibatch_index)\n",
    "\n",
    "            # =================================\n",
    "            # ２．３．訓練結果の検証\n",
    "            # =================================\n",
    "            \n",
    "            # validation_frequency回の更新ごとにバリデーションセットによるモデル検証が入る\n",
    "            iteration = (epoch - 1) * n_train_batches + minibatch_index\n",
    "            if (iteration + 1) % validation_frequency == 0:\n",
    "                # バリデーションセットの平均エラー率を計算\n",
    "                validation_losses = [\n",
    "                    validate_model(i) for i in xrange(n_valid_batches)]\n",
    "                this_validation_loss = np.mean(validation_losses)\n",
    "                print \"epoch %i, minibatch %i/%i, validation error %f %%\" % \\\n",
    "                    (epoch, minibatch_index + 1, n_train_batches,\n",
    "                     this_validation_loss * 100)\n",
    "\n",
    "            # patienceを超えたらループを終了\n",
    "            if patience <= iteration:\n",
    "                done_looping = True\n",
    "                break\n",
    "\n",
    "    end_time = time.clock()\n",
    "    print \"Optimization complete with best validation score of %f %%, \" \\\n",
    "        \"with test performance %f %%\" % \\\n",
    "        (best_validation_loss * 100, test_score * 100)\n",
    "    print \"The code run for %d epochs, with %f epochs/sec\" % \\\n",
    "        (epoch, 1.0 * epoch / (end_time - start_time))\n",
    "    with open(\"weight.txt\", \"w\") as f:\n",
    "        strOut = \"\"\n",
    "        res = classifier.W.get_value(borrow=True)\n",
    "        for i in range(len(res)):\n",
    "            strOut += str(res[i])\n",
    "        f.write(strOut)\n",
    "    \n",
    "    import cv2\n",
    "    _n = 0\n",
    "    minibatch_index = 0\n",
    "    res = test_image(minibatch_index) # 600データ引っ張ってくる? len(res) => 600\n",
    "    for i in range(len(res)):\n",
    "        cv2.imwrite(\"output/num_{n}.png\".format(n=_n), np.reshape(res[i], (28,28))*255)\n",
    "        _n += 1\n",
    "        print(\"output[{n}] is :\".format(n=_n))\n",
    "        print(test_output(minibatch_index)[i])\n",
    "        \n",
    "    print(n_train_batches)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sgd_optimization_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-2-76738cbee0eb>\u001b[0m(94)\u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     93 \u001b[1;33m    \u001b[1;31m# データのフォーマットを確認してみよう！\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 94 \u001b[1;33m    \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhogehogehoge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     95 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> type(test_set)\n",
      "<type 'tuple'>\n",
      "ipdb> len(test_set)\n",
      "2\n",
      "ipdb> test_set[0]\n",
      "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)\n",
      "ipdb> test_set[1]\n",
      "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)\n",
      "ipdb> len(test_set[0])\n",
      "10000\n",
      "ipdb> len(test_set[0][0])\n",
      "784\n",
      "ipdb> len(train_set[0])\n",
      "50000\n",
      "ipdb> len(train_set[0][1])\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
